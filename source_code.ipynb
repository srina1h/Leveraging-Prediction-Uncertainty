{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSeSpcCxXtxY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k6heuxnTTZFH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import text, sequence\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import gc \n",
    "import re\n",
    "import time\n",
    "np.set_printoptions(suppress=True)\n",
    "from scipy.special import erfinv\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9V9i6M1XvfF"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g203y-FFfrTF"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"DataSplit/train.tsv\", delimiter=\"\\t\", dtype={0:'str',1:'str'})\n",
    "test_df = pd.read_csv(\"DataSplit/test.tsv\", delimiter=\"\\t\", dtype={0:'str',1:'str'})\n",
    "val_df = pd.read_csv(\"DataSplit/test.tsv\", delimiter=\"\\t\", dtype={0:'str',1:'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8rJROH_WGbQ"
   },
   "source": [
    "# Tokenizing and generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0-Xo4j9T3WV"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'GloVe/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ku_0zQrqUeRI"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eckuxzKSXDuj"
   },
   "source": [
    "## Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vrjtGtFgUJsL"
   },
   "outputs": [],
   "source": [
    "max_features = 180000\n",
    "maxlen = 400\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(data_df['Plot Summary'])\n",
    "\n",
    "tokenized_train = tokenizer.texts_to_sequences(data_df['Plot Summary'])\n",
    "train_dataset = sequence.pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "\n",
    "tokenized_test = tokenizer.texts_to_sequences(test_df['Plot Summary'])\n",
    "test_dataset = sequence.pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "\n",
    "tokenized_val = tokenizer.texts_to_sequences(val_df['Plot Summary'])\n",
    "val_dataset = sequence.pad_sequences(tokenized_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWFZb4UhXJdc"
   },
   "source": [
    "## Generating Embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M0RR3COT5la"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqXFSKy-WVGW",
    "outputId": "50fee716-3ab8-476c-cadd-711ffbdbab9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "embed_size = 300\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "#embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, 50))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "\n",
    "c = 0\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words: continue\n",
    "    c += 1\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0N-vEs4XAtm"
   },
   "source": [
    "## Cleaning up to save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuArE1dorEkr",
    "outputId": "95ee6cca-71be-4ace-a7b0-099755cf67c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del all_embs\n",
    "del embeddings_index\n",
    "del tokenized_train\n",
    "del tokenized_test\n",
    "del tokenized_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xdD2_aSaPZB"
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z_P95YR4EnCW"
   },
   "outputs": [],
   "source": [
    "def make_one_hot_separate_cols(no_classes, dataframe):\n",
    "    \"\"\"\n",
    "    Given a dataframe with column containing one-hot-encoding of type 010010 \n",
    "    (single column one hot vector). Splits it into multiple columns depending\n",
    "    on number of classes specified (no_classes). Returns array containing\n",
    "    no_classes number of cols and same number of rows as dataframe.\n",
    "    \"\"\"\n",
    "    columns = [i for i in range(1,no_classes + 1)]\n",
    "    genres = []\n",
    "    for item in dataframe['Encoded Genres']:\n",
    "        splits = []\n",
    "        n = len(item)\n",
    "        while n + len(splits) < no_classes:\n",
    "            splits.append(0)\n",
    "        for i in item:\n",
    "            splits.append(int(i))\n",
    "        genres.append(splits)\n",
    "    separated = pd.DataFrame(genres, columns = columns)\n",
    "    return separated.to_numpy()\n",
    "\n",
    "def threshold_predictions(predictions, threshold):\n",
    "    \"\"\"\n",
    "    Function to threshold predictions matrix and make values below threshold\n",
    "    as 0 and values >= threshold as 1.\n",
    "    \"\"\"\n",
    "    predictions[predictions >= threshold] = 1\n",
    "    predictions[predictions < threshold] = 0\n",
    "    return predictions\n",
    "\n",
    "def Eval_MC_Dropouts(save_path, no_of_reps, X_test, Y_test, threshold_value, confidence_threshold, conf_perc_factor):\n",
    "    \"\"\"\n",
    "    Runs over no_of_reps times to create different models using MC dropouts and\n",
    "    predicts a different set of probabilites during each repetition.\n",
    "    \n",
    "    Returns average of all predictions taken over no_of_reps number of predict-\n",
    "    ions, stanadard deviation across all predictions taken over no_of_reps num-\n",
    "    ber of predictions and the F1 score for each model.\n",
    "    \"\"\"\n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    f1_list = [] # array of shape no_of_reps x 1 (F1 score)\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, Y_test.shape[0], Y_test.shape[1])) # 3D array to store all no_of_reps number of different prediction values\n",
    "    model = tf.keras.models.load_model(save_path)\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        predictions = model.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        model_f1 = eval_model(thresholded_predictions, Y_test) # returns f1 of model\n",
    "        f1_list.append(model_f1)\n",
    "    avg_f1 = np.mean(np.array(f1_list), axis = 0)\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average stddev of all reps)\n",
    "    now = datetime.datetime.now()\n",
    "    name = 'MC_Values/'+str(now.month)+\"-\"+str(now.day)+\"-\"+str(now.hour)+\"-\"+str(now.minute)+\"_\"+str(no_of_reps)+\"_\" # file nomenclature\n",
    "    pd.DataFrame(avg_prediction_array).to_csv(name+'average_preds.csv', index = False, header = None)\n",
    "    pd.DataFrame(std_prediction_array).to_csv(name+'std_preds.csv', index = False, header = None) # saving prediction avg and std over no_of_reps\n",
    "    # Fequentist calculation\n",
    "    final_predictions_freq = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            avg = avg_prediction_array[i,j]\n",
    "            std = std_prediction_array[i,j]\n",
    "            lower_lim = avg - conf_level_factor*std\n",
    "            upper_lim = avg + conf_level_factor*std\n",
    "            if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "                final_predictions_freq[i,j] = 1\n",
    "            elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "                final_predictions_freq[i,j] = 0\n",
    "            else: \n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_predictions_freq.append(final_predictions_freq[i])\n",
    "            selected_Y_vals_freq.append(Y_test[i])\n",
    "    selected_freq_preds_f1 = eval_model(np.array(thresholded_predictions_freq), np.array(selected_Y_vals_freq), printing = False)\n",
    "    # Frequentist calculation ends\n",
    "    avg_thresholded_predictions = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    avg_pred_f1 = eval_model(avg_thresholded_predictions, Y_test, printing = False) # returns f1 of Averaged predictions from no_of_reps models\n",
    "    avg_pred_precision = precision_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    avg_pred_recall = recall_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    all_prediction_array_thresholded = threshold_predictions(all_prediction_array, threshold_value)\n",
    "    confidence_matrix = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    final_predictions_maj_vote = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    print(all_prediction_array_thresholded.shape)\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            no_of_zeros = 0\n",
    "            no_of_ones = 0\n",
    "            for k in range(no_of_reps):\n",
    "                if all_prediction_array_thresholded[k,i,j] == 0:\n",
    "                    no_of_zeros += 1\n",
    "                elif all_prediction_array_thresholded[k,i,j] == 1:\n",
    "                    no_of_ones += 1\n",
    "            if no_of_ones > no_of_zeros:\n",
    "                confidence_matrix[i, j] = no_of_ones/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 1\n",
    "            else:\n",
    "                confidence_matrix[i, j] = no_of_zeros/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 0\n",
    "    thresholded_confidence_predictions = []\n",
    "    selected_ground_truth_values = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            if confidence_matrix[i, j] < confidence_threshold:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_confidence_predictions.append(final_predictions_maj_vote[i])\n",
    "            selected_ground_truth_values.append(Y_test[i])\n",
    "    avg_f1_conf_thresholded = eval_model(np.array(thresholded_confidence_predictions), np.array(selected_ground_truth_values), printing = False)\n",
    "\n",
    "    f1_maj_vote = eval_model(np.array(final_predictions_maj_vote), Y_test, printing = False)\n",
    "\n",
    "    print(\"Max F1 score of all reps: \"+str(max(f1_list)))\n",
    "    print(\"Average F1 score of all reps: \"+str(avg_f1))\n",
    "    print(\"F1 Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_f1))\n",
    "    print(\"Precision Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_precision))\n",
    "    print(\"Recall Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_recall))\n",
    "    print(\"-----\\nApplying confidence thresholding - F1 score of selected predictions: \"+str(avg_f1_conf_thresholded))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_ground_truth_values).shape[0]))\n",
    "    print(\"-----\\nApplying frequentist methods - F1 score of selected predictions: \"+str(selected_freq_preds_f1))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_Y_vals_freq).shape[0]))\n",
    "    print(\"Majority vote F1:\"+str(f1_maj_vote))\n",
    "    return avg_prediction_array, std_prediction_array, f1_list\n",
    "\n",
    "def eval_model(predictions, truths, printing = True):\n",
    "    \"\"\"\n",
    "    Function to evaluate a single models' predictions. Prints F1, precision and \n",
    "    recall score of model on the test set. returns model F1 score.\n",
    "    \"\"\"\n",
    "    if type(truths) is not np.ndarray:\n",
    "        truths = np.array(truths)\n",
    "    if type(predictions) is not np.ndarray:\n",
    "        predictions = np.array(predictions)\n",
    "    model_f1 = f1_score(predictions, truths, average='micro')\n",
    "    model_precision = precision_score(predictions, truths, average='micro')\n",
    "    model_recall = recall_score(predictions, truths, average='micro')\n",
    "    if printing:\n",
    "        print(\"\\nModel F1 on test data is: \"+str(model_f1))\n",
    "        print(\"Model Precision on test data is: \"+str(model_precision))\n",
    "        print(\"Model Recall on test data is: \"+str(model_recall))\n",
    "    return model_f1\n",
    "\n",
    "def train_model_ensembling(X_train, Y_train, save_folder, no_of_reps = 10, epochs_per_model = 7):\n",
    "    \"\"\"\n",
    "    Takes X_train, Y_train, Saved models folder, no_of_reps and epochs per model\n",
    "    as arguments and trains no_of_reps models and saves them into the appropria-\n",
    "    te folder. Numbered from 1 - no_of_reps. NOTE: get_model() function must be\n",
    "    defined with the appropriate model to be ensembled.\n",
    "    \"\"\"\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        model_itr = get_model()\n",
    "        model_itr.fit(X_train, Y_train, batch_size = 128, validation_data = (val_dataset, Y_val), epochs = epochs_per_model, workers = 4, use_multiprocessing = True)\n",
    "        path = str(save_folder)+str(i+1)+\"_EN_BiLSTM.h5\" # file nomenclature\n",
    "        model_itr.save(path)\n",
    "    return\n",
    "\n",
    "def eval_model_ensembling(save_folder, no_of_reps, X_test, Y_test, threshold_value, confidence_threshold, conf_perc_factor):\n",
    "    \"\"\"\n",
    "    Evaluates ensembled models stored in save_folder path. Loads each model num-\n",
    "    bered from 1-no_of_reps and predicts no_of_reps number of different output \n",
    "    predictions.\n",
    "\n",
    "    Returns average of all predictions taken over no_of_reps number of predict-\n",
    "    ions, stanadard deviation across all predictions taken over no_of_reps num-\n",
    "    ber of predictions and the F1 score for each model.\n",
    "    \"\"\"\n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    f1_list = [] # array of shape no_of_reps x 1 (F1 score)\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, Y_test.shape[0], Y_test.shape[1])) # 3D array to store all no_of_reps number of different prediction values\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        path = str(save_folder)+str(i+1)+\"_EN_BiLSTM.h5\"\n",
    "        model_itr = tf.keras.models.load_model(path)\n",
    "        predictions = model_itr.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        model_f1 = eval_model(thresholded_predictions, Y_test) # returns f1 of model\n",
    "        f1_list.append(model_f1)\n",
    "    avg_f1 = np.mean(np.array(f1_list), axis = 0)\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average stddev of all reps)\n",
    "    now = datetime.datetime.now()\n",
    "    name = 'EN_Values/'+str(now.month)+\"-\"+str(now.day)+\"-\"+str(now.hour)+\"-\"+str(now.minute)+\"_\"+str(no_of_reps)+\"_\" # file nomenclature\n",
    "    pd.DataFrame(avg_prediction_array).to_csv(name+'average_preds.csv', index = False, header = None)\n",
    "    pd.DataFrame(std_prediction_array).to_csv(name+'std_preds.csv', index = False, header = None) # saving prediction avg and std over no_of_reps\n",
    "    # Fequentist calculation\n",
    "    final_predictions_freq = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            avg = avg_prediction_array[i,j]\n",
    "            std = std_prediction_array[i,j]\n",
    "            lower_lim = avg - conf_level_factor*std\n",
    "            upper_lim = avg + conf_level_factor*std\n",
    "            if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "                final_predictions_freq[i,j] = 1\n",
    "            elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "                final_predictions_freq[i,j] = 0\n",
    "            else: \n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_predictions_freq.append(final_predictions_freq[i])\n",
    "            selected_Y_vals_freq.append(Y_test[i])\n",
    "    selected_freq_preds_f1 = eval_model(np.array(thresholded_predictions_freq), np.array(selected_Y_vals_freq), printing = False)\n",
    "    # Frequentist calculation ends\n",
    "    avg_thresholded_predictions = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    avg_pred_f1 = eval_model(avg_thresholded_predictions, Y_test) # returns f1 of Averaged predictions from no_of_reps models\n",
    "    avg_pred_precision = precision_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    avg_pred_recall = recall_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    all_prediction_array_thresholded = threshold_predictions(all_prediction_array, threshold_value)\n",
    "    confidence_matrix = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    final_predictions_maj_vote = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    print(all_prediction_array_thresholded.shape)\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            no_of_zeros = 0\n",
    "            no_of_ones = 0\n",
    "            for k in range(no_of_reps):\n",
    "                if all_prediction_array_thresholded[k,i,j] == 0:\n",
    "                    no_of_zeros += 1\n",
    "                elif all_prediction_array_thresholded[k,i,j] == 1:\n",
    "                    no_of_ones += 1\n",
    "            if no_of_ones > no_of_zeros:\n",
    "                confidence_matrix[i, j] = no_of_ones/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 1\n",
    "            else:\n",
    "                confidence_matrix[i, j] = no_of_zeros/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 0\n",
    "    thresholded_confidence_predictions = []\n",
    "    selected_ground_truth_values = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            if confidence_matrix[i, j] < confidence_threshold:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_confidence_predictions.append(final_predictions_maj_vote[i])\n",
    "            selected_ground_truth_values.append(Y_test[i])\n",
    "    avg_f1_conf_thresholded = eval_model(np.array(thresholded_confidence_predictions), np.array(selected_ground_truth_values), printing = False)\n",
    "\n",
    "    f1_maj_vote = eval_model(np.array(final_predictions_maj_vote), Y_test, printing = False)\n",
    "\n",
    "    print(\"Max F1 score of all reps: \"+str(max(f1_list)))\n",
    "    print(\"Average F1 score of all reps: \"+str(avg_f1))\n",
    "    print(\"F1 Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_f1))\n",
    "    print(\"Precision Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_precision))\n",
    "    print(\"Recall Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_recall))\n",
    "    print(\"-----\\nApplying confidence thresholding- F1 score of selected predictions: \"+str(avg_f1_conf_thresholded))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_ground_truth_values).shape[0]))\n",
    "    print(\"-----\\nApplying frequentist methods - F1 score of selected predictions: \"+str(selected_freq_preds_f1))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_Y_vals_freq).shape[0]))\n",
    "    print(\"Majority vote F1:\"+str(f1_maj_vote))\n",
    "    return avg_prediction_array, std_prediction_array, f1_list\n",
    "\n",
    "def single_EN_pred(save_folder, no_of_reps, X_test, Y_test, threshold_value, num_classes, maxlen_embedding, conf_perc_factor):\n",
    "    \"\"\"\n",
    "    Takes a single training example as input along with no_of_reps to predict n-\n",
    "    o_of_reps number of inferences \n",
    "    \"\"\"\n",
    "    if X_test.shape is not (1, maxlen_embedding):\n",
    "        X_test = np.reshape(X_test, (1, maxlen_embedding))\n",
    "    if Y_test.shape is not (1, num_classes):\n",
    "        Y_test = np.reshape(Y_test, (1, num_classes))\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, 1, num_classes)) # 3D array to store all no_of_reps number of different prediction values\n",
    "    confidence_count_zero = [0 for i in range(num_classes)]\n",
    "    confidence_count_one = [0 for i in range(num_classes)]\n",
    "    confidence_factor = [0 for i in range(num_classes)]\n",
    "    final_prediction_MV = [0 for i in range(num_classes)]\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        path = str(save_folder)+str(i+1)+\"_EN_BiLSTM.h5\"\n",
    "        model_itr = tf.keras.models.load_model(path)\n",
    "        predictions = model_itr.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        print(thresholded_predictions)\n",
    "        for i in range(thresholded_predictions.shape[1]):\n",
    "            if thresholded_predictions[0][i] == 0:\n",
    "                confidence_count_zero[i] += 1\n",
    "            else:\n",
    "                confidence_count_one[i] += 1\n",
    "    for i in range(num_classes):\n",
    "        if confidence_count_zero[i] > confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_zero[i] / no_of_reps)*100\n",
    "        elif confidence_count_zero[i] < confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_one[i] / no_of_reps)*100\n",
    "            final_prediction_MV[i] = 1\n",
    "        else:\n",
    "            confidence_factor[i] =  50.0\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average stddev of all reps)\n",
    "    # frequentist starts \n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    final_predictions_freq = np.zeros(shape = (1, num_classes))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    lower_lim_array = []\n",
    "    upper_lim_array = []\n",
    "    flag = 0\n",
    "    for j in range(num_classes):\n",
    "        avg = avg_prediction_array[0,j]\n",
    "        std = std_prediction_array[0,j]\n",
    "        lower_lim = avg - conf_level_factor*std\n",
    "        upper_lim = avg + conf_level_factor*std\n",
    "        lower_lim_array.append(lower_lim)\n",
    "        upper_lim_array.append(upper_lim)\n",
    "        if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "            final_predictions_freq[0,j] = 1\n",
    "        elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "            final_predictions_freq[0,j] = 0\n",
    "        else: \n",
    "            flag = 1\n",
    "    if flag == 0:\n",
    "        thresholded_predictions_freq.append(final_predictions_freq[0])\n",
    "    #frequentist ends\n",
    "    avg_prediction_thresholded = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    genres_list = ['Spy Fiction', 'Alternate History', 'Non Fiction', 'Adevnture Novel', 'Detective Fiction', 'Historical Fiction', 'Romance Novel', 'Horror', 'Thriller', 'Historical Novel', 'Crime Fiction', 'Suspense', 'Young Adult Literature', 'Mystery', 'Childrens Literature', 'Fantasy', 'Novel', 'Science Fiction', 'Speculative Fiction', 'Fiction']\n",
    "    answer_list = []\n",
    "    ground_truth_list = []\n",
    "    for i in range(20):\n",
    "        if avg_prediction_thresholded[0][i] == 1:\n",
    "            answer_list.append(genres_list[i])\n",
    "        if Y_test[0][i] == 1:\n",
    "            ground_truth_list.append(genres_list[i])\n",
    "    print(\"Majority Vote Prediction of all models: \")\n",
    "    print(final_prediction_MV)\n",
    "    print(\"Ground truth Value: \")\n",
    "    print(Y_test)\n",
    "    print(\"Ground truth class labels: \")\n",
    "    print(ground_truth_list)\n",
    "    print(\"Final prediction after confidence interval thresholding: \")\n",
    "    print(final_predictions_freq)\n",
    "    print(\"Confidence factors for each class: \")\n",
    "    for i in range(num_classes):\n",
    "        print(\"(\",lower_lim_array[i],\", \",upper_lim_array[i],\")\")\n",
    "    if flag == 0:\n",
    "        print(\"Prediction passes - CONSIDERED\")\n",
    "    else:\n",
    "        print(\"prediction fails - IGNORED\")\n",
    "    return avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor\n",
    "\n",
    "def single_MC_pred(save_path, no_of_reps, X_test, Y_test, threshold_value, num_classes, maxlen_embedding, conf_perc_factor):\n",
    "    if X_test.shape is not (1, maxlen_embedding):\n",
    "        X_test = np.reshape(X_test, (1, maxlen_embedding))\n",
    "    if Y_test.shape is not (1, num_classes):\n",
    "        Y_test = np.reshape(Y_test, (1, num_classes))\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, 1, num_classes)) # 3D array to store all no_of_reps number of different prediction values\n",
    "    confidence_count_zero = [0 for i in range(num_classes)]\n",
    "    confidence_count_one = [0 for i in range(num_classes)]\n",
    "    confidence_factor = [0 for i in range(num_classes)]\n",
    "    final_prediction_MV = [0 for i in range(num_classes)]\n",
    "    loaded_model = tf.keras.models.load_model(save_path)\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        predictions = loaded_model.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        print(thresholded_predictions)\n",
    "        for i in range(thresholded_predictions.shape[1]):\n",
    "            if thresholded_predictions[0][i] == 0:\n",
    "                confidence_count_zero[i] += 1\n",
    "            else:\n",
    "                confidence_count_one[i] += 1\n",
    "    for i in range(num_classes):\n",
    "        if confidence_count_zero[i] > confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_zero[i] / no_of_reps)*100\n",
    "        elif confidence_count_zero[i] < confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_one[i] / no_of_reps)*100\n",
    "            final_prediction_MV[i] = 1\n",
    "        else:\n",
    "            confidence_factor[i] =  50.0\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average stddev of all reps)\n",
    "    # frequentist starts \n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    final_predictions_freq = np.zeros(shape = (1, num_classes))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    lower_lim_array = []\n",
    "    upper_lim_array = []\n",
    "    flag = 0\n",
    "    for j in range(num_classes):\n",
    "        avg = avg_prediction_array[0,j]\n",
    "        std = std_prediction_array[0,j]\n",
    "        lower_lim = avg - conf_level_factor*std\n",
    "        upper_lim = avg + conf_level_factor*std\n",
    "        lower_lim_array.append(lower_lim)\n",
    "        upper_lim_array.append(upper_lim)\n",
    "        if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "            final_predictions_freq[0,j] = 1\n",
    "        elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "            final_predictions_freq[0,j] = 0\n",
    "        else: \n",
    "            flag = 1\n",
    "    if flag == 0:\n",
    "        thresholded_predictions_freq.append(final_predictions_freq[0])\n",
    "    #frequentist ends\n",
    "    avg_prediction_thresholded = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    genres_list = ['Spy Fiction', 'Alternate History', 'Non Fiction', 'Adevnture Novel', 'Detective Fiction', 'Historical Fiction', 'Romance Novel', 'Horror', 'Thriller', 'Historical Novel', 'Crime Fiction', 'Suspense', 'Young Adult Literature', 'Mystery', 'Childrens Literature', 'Fantasy', 'Novel', 'Science Fiction', 'Speculative Fiction', 'Fiction']\n",
    "    answer_list = []\n",
    "    ground_truth_list = []\n",
    "    for i in range(20):\n",
    "        if avg_prediction_thresholded[0][i] == 1:\n",
    "            answer_list.append(genres_list[i])\n",
    "        if Y_test[0][i] == 1:\n",
    "            ground_truth_list.append(genres_list[i])\n",
    "    print(\"Majority Vote Prediction of all models: \")\n",
    "    print(final_prediction_MV)\n",
    "    print(\"Ground truth Value: \")\n",
    "    print(Y_test)\n",
    "    print(\"Ground truth class labels: \")\n",
    "    print(ground_truth_list)\n",
    "    print(\"Final prediction after confidence interval thresholding: \")\n",
    "    print(final_predictions_freq)\n",
    "    print(\"Confidence factors for each class: \")\n",
    "    for i in range(num_classes):\n",
    "        print(\"(\",lower_lim_array[i],\", \",upper_lim_array[i],\")\")\n",
    "    if flag == 0:\n",
    "        print(\"Prediction passes - CONSIDERED\")\n",
    "    else:\n",
    "        print(\"prediction fails - IGNORED\")\n",
    "    return avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYOX8p80X7Ws"
   },
   "source": [
    "# Preprocessing Labels to feed into network Training, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "be0RGfxTYDw1"
   },
   "outputs": [],
   "source": [
    "Y_train = make_one_hot_separate_cols(20, data_df)\n",
    "Y_val = make_one_hot_separate_cols(20, val_df)\n",
    "Y_test = make_one_hot_separate_cols(20, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TdNmCKKWYiv"
   },
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBmYpMilWhLn"
   },
   "source": [
    "## Model with NO Inference time dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnNhjn-AYLKS"
   },
   "outputs": [],
   "source": [
    "def get_model(lr=0.001):\n",
    "    model = tf.keras.models.Sequential(name = \"BiLSTM_Model\")\n",
    "    model.add(tf.keras.layers.Embedding(nb_words, output_dim=embed_size, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.1)) # embedding dropouts\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, recurrent_dropout = 0.5, activation = 'tanh')))# weight drop on recurrent layers using recurrent_dropout\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D(data_format=\"channels_last\", keepdims=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(20))\n",
    "    model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=False) , optimizer = 'adam', metrics = ['accuracy', tfa.metrics.F1Score(num_classes = 20, average = 'micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cHVThvOWbi2"
   },
   "source": [
    "## Model With Inference Time dropouts Enabled (MC Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P84hx4of5yRK"
   },
   "outputs": [],
   "source": [
    "def get_model(lr=0.001):\n",
    "    inputs = tf.keras.layers.Input(shape=(maxlen,))\n",
    "    x = tf.keras.layers.Embedding(nb_words, output_dim=embed_size, weights=[embedding_matrix], input_length = maxlen, trainable=False)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x, training = True) # embedding dropouts\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, recurrent_dropout = 0.5, activation = 'tanh'))(x)# weight drop on recurrent layers using recurrent_dropout\n",
    "    x = tf.keras.layers.GlobalMaxPooling1D(data_format=\"channels_last\", keepdims=False)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x, training = True)\n",
    "    x = tf.keras.layers.Dense(512)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.Dense(20)(x)\n",
    "    outputs = tf.keras.layers.Activation('sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"BiLSTM_MC_Model\")\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=False) , optimizer = 'adam', metrics = ['accuracy', tfa.metrics.F1Score(num_classes = 20, average = 'micro')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdHUVPJ5oPgR",
    "outputId": "4f2e4baa-fa34-45ad-eaac-3a712f0cef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"BiLSTM_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 400, 300)          34723800  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 400, 300)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 400, 512)         1140736   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 512)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                10260     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,137,452\n",
      "Trainable params: 1,413,652\n",
      "Non-trainable params: 34,723,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XN2Aec1sYY5j"
   },
   "source": [
    "# Training and Saving Model (Training and saving SINGLE Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrDdgPV_TCV4"
   },
   "source": [
    "## Train MC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVHgJk7vTENc",
    "outputId": "d94dc4a9-bcfd-477f-c803-89106c781e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "81/81 [==============================] - 104s 1s/step - loss: 0.2873 - accuracy: 0.1606 - f1_score: 0.2705 - val_loss: 0.2543 - val_accuracy: 0.2004 - val_f1_score: 0.3272\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2398 - accuracy: 0.2748 - f1_score: 0.3459 - val_loss: 0.2329 - val_accuracy: 0.3058 - val_f1_score: 0.3635\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2248 - accuracy: 0.3006 - f1_score: 0.3621 - val_loss: 0.2249 - val_accuracy: 0.2700 - val_f1_score: 0.3504\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2159 - accuracy: 0.3185 - f1_score: 0.3762 - val_loss: 0.2185 - val_accuracy: 0.3240 - val_f1_score: 0.3728\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2079 - accuracy: 0.3286 - f1_score: 0.3861 - val_loss: 0.2162 - val_accuracy: 0.3339 - val_f1_score: 0.3782\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2022 - accuracy: 0.3437 - f1_score: 0.3972 - val_loss: 0.2130 - val_accuracy: 0.3229 - val_f1_score: 0.3806\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.1968 - accuracy: 0.3501 - f1_score: 0.4032 - val_loss: 0.2100 - val_accuracy: 0.3110 - val_f1_score: 0.3819\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.1914 - accuracy: 0.3584 - f1_score: 0.4119 - val_loss: 0.2086 - val_accuracy: 0.2965 - val_f1_score: 0.3806\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.1884 - accuracy: 0.3692 - f1_score: 0.4176 - val_loss: 0.2111 - val_accuracy: 0.3287 - val_f1_score: 0.3759\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1835 - accuracy: 0.3752 - f1_score: 0.4238 - val_loss: 0.2063 - val_accuracy: 0.3468 - val_f1_score: 0.3886\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1787 - accuracy: 0.3896 - f1_score: 0.4336 - val_loss: 0.2089 - val_accuracy: 0.3442 - val_f1_score: 0.3899\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1746 - accuracy: 0.3954 - f1_score: 0.4429 - val_loss: 0.2095 - val_accuracy: 0.3172 - val_f1_score: 0.3879\n"
     ]
    }
   ],
   "source": [
    "batchsize = 128\n",
    "history = model.fit(train_dataset, Y_train, batch_size = batchsize, validation_data = (val_dataset, Y_val), initial_epoch = 0, epochs = 12, workers = 4, use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUEZLR9oTHdt",
    "outputId": "07fb96b5-8e2d-457b-f5fe-f0270c86b4b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4756687077022236"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(test_dataset)\n",
    "preds = threshold_predictions(preds, 0.5)\n",
    "f1_score(preds, Y_test, average = 'micro') # MC (12 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T13RniEYTIvi"
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "name = 'Models/'+str(now.month)+\"-\"+str(now.day)+\"-\"+str(now.hour)+\"-\"+str(now.minute)+\"_MC_BiLSTM.h5\" # file nomenclature\n",
    "model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMkZP_6tYdRH"
   },
   "source": [
    "# Evaluating Model Uncertainty (MC dropout based eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiIe8k4SEd0K"
   },
   "source": [
    "## MC eval of entire dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dxCSgCkdapC"
   },
   "source": [
    "SETTING frequentist confidence factor to 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCkvDQvndnph",
    "outputId": "6c668e07-04e1-43e2-c68a-502c5f56fa72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:10<01:35, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.4695484493009802\n",
      "Model Precision on test data is: 0.36172319881158704\n",
      "Model Recall on test data is: 0.6689560439560439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:20<01:23, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.46769527483124407\n",
      "Model Precision on test data is: 0.3602376825947017\n",
      "Model Recall on test data is: 0.6665139715987174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:31<01:12, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.47106109324758844\n",
      "Model Precision on test data is: 0.36271354295617725\n",
      "Model Recall on test data is: 0.6717102246675837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:41<01:01, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.4608960976393127\n",
      "Model Precision on test data is: 0.35528596187175043\n",
      "Model Recall on test data is: 0.6558500914076782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:51<00:51, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.46771602955348535\n",
      "Model Precision on test data is: 0.36048526863084923\n",
      "Model Recall on test data is: 0.6657521719250115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:01<00:40, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.4788553259141494\n",
      "Model Precision on test data is: 0.3728645704382273\n",
      "Model Recall on test data is: 0.669035984007108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [01:11<00:30, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.474451385551818\n",
      "Model Precision on test data is: 0.36667491953453824\n",
      "Model Recall on test data is: 0.6719600725952813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:22<00:20, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.4714584338318058\n",
      "Model Precision on test data is: 0.36296112899232486\n",
      "Model Recall on test data is: 0.6724770642201835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:32<00:10, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.47162270183852917\n",
      "Model Precision on test data is: 0.36518940331765287\n",
      "Model Recall on test data is: 0.6656137184115524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:42<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.4694337194337195\n",
      "Model Precision on test data is: 0.3612280267392919\n",
      "Model Recall on test data is: 0.6701883325677538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1926, 20)\n",
      "Max F1 score of all reps: 0.4788553259141494\n",
      "Average F1 score of all reps: 0.47027385111426323\n",
      "F1 Score from ALL Models' predictions AVERAGED: 0.4700613700447836\n",
      "Precision Score from ALL Models' predictions AVERAGED: 0.35082941322109434\n",
      "Recall Score from ALL Models' predictions AVERAGED: 0.7120603015075377\n",
      "-----\n",
      "Applying confidence thresholding - F1 score of selected predictions: 0.5600739371534196\n",
      "Predictions Refused: 1565\n",
      "-----\n",
      "Applying frequentist methods - F1 score of selected predictions: 0.539906103286385\n",
      "Predictions Refused: 1497\n"
     ]
    }
   ],
   "source": [
    "path = 'Models/MC_BiLSTM.h5'\n",
    "avg_prediction_array, std_prediction_array, avg_f1_array = Eval_MC_Dropouts(path, 10, test_dataset, Y_test, 0.5, 100, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDJgCy2LlCQT"
   },
   "source": [
    "## Single sample MC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ow2lkCSdcY0",
    "outputId": "0352dc36-25a2-441c-cb3b-97e4bf20eec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoded Genres                                 00000000000000110000\n",
       "Plot Summary       After more than three years in exile on Grays...\n",
       "Name: 35, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Vg6cpLpXjmM",
    "outputId": "176805b9-7d1e-432d-cc94-e62b8e1a2dfb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▊                                                                                                 | 1/10 [00:01<00:13,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████████████████████▌                                                                                      | 2/10 [00:01<00:06,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████████████▍                                                                           | 3/10 [00:02<00:04,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████████████████▏                                                                | 4/10 [00:02<00:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████████████                                                      | 5/10 [00:03<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████▊                                           | 6/10 [00:03<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████████████████████████▌                                | 7/10 [00:04<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████████████████████████▍                     | 8/10 [00:04<00:01,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████▏          | 9/10 [00:05<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n",
      "Majority Vote Prediction of all models: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "Ground truth Value: \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]]\n",
      "Ground truth class labels: \n",
      "['Childrens Literature', 'Fantasy']\n",
      "Final prediction after confidence interval thresholding: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]]\n",
      "Confidence factors for each class: \n",
      "( -0.0039299078358248155 ,  0.07093572095762046 )\n",
      "( 0.05140874564437163 ,  0.2975949209949564 )\n",
      "( -0.007082209357269033 ,  0.04443129635716222 )\n",
      "( -2.689394992610994e-06 ,  0.0002655769675275754 )\n",
      "( -3.3273947112933483e-06 ,  1.7535114193622034e-05 )\n",
      "( 0.10851591439960695 ,  0.19333998946429992 )\n",
      "( 0.07337166911806742 ,  0.27780889623914085 )\n",
      "( -0.00043164103904225074 ,  0.007084204849390761 )\n",
      "( -0.004665702171336057 ,  0.02046665508271301 )\n",
      "( -4.128841811507005e-05 ,  0.0003164840549379703 )\n",
      "( -0.0006335571226355164 ,  0.003027524035858783 )\n",
      "( -0.0010095342976872675 ,  0.006467603145343517 )\n",
      "( 0.007343608044870824 ,  0.09749090681146769 )\n",
      "( 0.0001769529004341144 ,  0.0018893195967430098 )\n",
      "( 0.8070770910345334 ,  0.9817692109979373 )\n",
      "( 0.6958268771707565 ,  0.8128831257284135 )\n",
      "( -0.0007757648986946979 ,  0.002668703514914606 )\n",
      "( -0.0006519145967722685 ,  0.003901643276429251 )\n",
      "( -0.0026760801409112787 ,  0.008658198985897241 )\n",
      "( -0.0006629046369286511 ,  0.00781332220322809 )\n",
      "Prediction passes - CONSIDERED\n",
      "Wall time: 9.13 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "saved_path = 'Models/MC_BiLSTM.h5'\n",
    "avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor = single_MC_pred(saved_path, 10, test_dataset[35], Y_test[35], 0.5, 20, 400, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Htrz4fBhgRBk"
   },
   "source": [
    "# Model Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dIUg1xhr0zC"
   },
   "source": [
    "## Training models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edRzCJApnHLf"
   },
   "source": [
    "Training 10 models and saving them into folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Zq2adTHgUsw",
    "outputId": "40beb8c3-dfbc-4e42-f154-34a33b215649"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 89s 1s/step - loss: 0.2846 - accuracy: 0.1556 - f1_score: 0.2775 - val_loss: 0.2506 - val_accuracy: 0.2175 - val_f1_score: 0.3306\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2384 - accuracy: 0.2821 - f1_score: 0.3460 - val_loss: 0.2304 - val_accuracy: 0.3240 - val_f1_score: 0.3574\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2228 - accuracy: 0.3117 - f1_score: 0.3686 - val_loss: 0.2249 - val_accuracy: 0.2918 - val_f1_score: 0.3685\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2133 - accuracy: 0.3251 - f1_score: 0.3803 - val_loss: 0.2133 - val_accuracy: 0.2887 - val_f1_score: 0.3849\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2072 - accuracy: 0.3336 - f1_score: 0.3896 - val_loss: 0.2142 - val_accuracy: 0.3224 - val_f1_score: 0.3886\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2019 - accuracy: 0.3388 - f1_score: 0.3949 - val_loss: 0.2063 - val_accuracy: 0.3297 - val_f1_score: 0.3943\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 80s 986ms/step - loss: 0.1970 - accuracy: 0.3485 - f1_score: 0.4041 - val_loss: 0.2051 - val_accuracy: 0.3370 - val_f1_score: 0.3896\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 80s 988ms/step - loss: 0.1925 - accuracy: 0.3621 - f1_score: 0.4110 - val_loss: 0.2047 - val_accuracy: 0.3266 - val_f1_score: 0.3846\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1874 - accuracy: 0.3620 - f1_score: 0.4160 - val_loss: 0.2018 - val_accuracy: 0.3510 - val_f1_score: 0.3966\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 80s 987ms/step - loss: 0.1837 - accuracy: 0.3743 - f1_score: 0.4238 - val_loss: 0.2045 - val_accuracy: 0.3567 - val_f1_score: 0.3866\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1791 - accuracy: 0.3819 - f1_score: 0.4275 - val_loss: 0.2044 - val_accuracy: 0.3375 - val_f1_score: 0.3923\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1753 - accuracy: 0.3904 - f1_score: 0.4376 - val_loss: 0.1985 - val_accuracy: 0.3629 - val_f1_score: 0.4013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [16:25<2:27:49, 985.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 94s 1s/step - loss: 0.2909 - accuracy: 0.1504 - f1_score: 0.2669 - val_loss: 0.2564 - val_accuracy: 0.2118 - val_f1_score: 0.3299\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2407 - accuracy: 0.2680 - f1_score: 0.3389 - val_loss: 0.2271 - val_accuracy: 0.3328 - val_f1_score: 0.3641\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 80s 992ms/step - loss: 0.2243 - accuracy: 0.3001 - f1_score: 0.3607 - val_loss: 0.2235 - val_accuracy: 0.3193 - val_f1_score: 0.3712\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 80s 990ms/step - loss: 0.2148 - accuracy: 0.3157 - f1_score: 0.3777 - val_loss: 0.2168 - val_accuracy: 0.2477 - val_f1_score: 0.3688\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.2084 - accuracy: 0.3274 - f1_score: 0.3862 - val_loss: 0.2110 - val_accuracy: 0.3354 - val_f1_score: 0.3842\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.2037 - accuracy: 0.3411 - f1_score: 0.3917 - val_loss: 0.2121 - val_accuracy: 0.3048 - val_f1_score: 0.3863\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1982 - accuracy: 0.3413 - f1_score: 0.4002 - val_loss: 0.2060 - val_accuracy: 0.3271 - val_f1_score: 0.3832\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1934 - accuracy: 0.3510 - f1_score: 0.4071 - val_loss: 0.2046 - val_accuracy: 0.3110 - val_f1_score: 0.3916\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1887 - accuracy: 0.3574 - f1_score: 0.4136 - val_loss: 0.2052 - val_accuracy: 0.3261 - val_f1_score: 0.3886\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1850 - accuracy: 0.3668 - f1_score: 0.4195 - val_loss: 0.2011 - val_accuracy: 0.3489 - val_f1_score: 0.4044\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.1799 - accuracy: 0.3833 - f1_score: 0.4321 - val_loss: 0.2000 - val_accuracy: 0.3629 - val_f1_score: 0.4027\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1761 - accuracy: 0.3868 - f1_score: 0.4332 - val_loss: 0.2010 - val_accuracy: 0.3354 - val_f1_score: 0.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [33:50<2:16:05, 1020.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2874 - accuracy: 0.1508 - f1_score: 0.2640 - val_loss: 0.2516 - val_accuracy: 0.1931 - val_f1_score: 0.3269\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2391 - accuracy: 0.2720 - f1_score: 0.3443 - val_loss: 0.2306 - val_accuracy: 0.3141 - val_f1_score: 0.3705\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2237 - accuracy: 0.3089 - f1_score: 0.3636 - val_loss: 0.2207 - val_accuracy: 0.3188 - val_f1_score: 0.3722\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 81s 997ms/step - loss: 0.2147 - accuracy: 0.3116 - f1_score: 0.3723 - val_loss: 0.2180 - val_accuracy: 0.3271 - val_f1_score: 0.3725\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2084 - accuracy: 0.3273 - f1_score: 0.3850 - val_loss: 0.2091 - val_accuracy: 0.3011 - val_f1_score: 0.3816\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 81s 997ms/step - loss: 0.2034 - accuracy: 0.3335 - f1_score: 0.3908 - val_loss: 0.2072 - val_accuracy: 0.3323 - val_f1_score: 0.3956\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 81s 1000ms/step - loss: 0.1981 - accuracy: 0.3457 - f1_score: 0.4009 - val_loss: 0.2051 - val_accuracy: 0.3557 - val_f1_score: 0.3923\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1940 - accuracy: 0.3516 - f1_score: 0.4072 - val_loss: 0.2026 - val_accuracy: 0.3339 - val_f1_score: 0.3909\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 81s 995ms/step - loss: 0.1887 - accuracy: 0.3682 - f1_score: 0.4189 - val_loss: 0.2054 - val_accuracy: 0.3650 - val_f1_score: 0.3987\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 81s 998ms/step - loss: 0.1848 - accuracy: 0.3666 - f1_score: 0.4165 - val_loss: 0.2050 - val_accuracy: 0.3411 - val_f1_score: 0.3980\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1808 - accuracy: 0.3803 - f1_score: 0.4284 - val_loss: 0.2028 - val_accuracy: 0.3261 - val_f1_score: 0.3923\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1762 - accuracy: 0.3871 - f1_score: 0.4351 - val_loss: 0.2015 - val_accuracy: 0.3479 - val_f1_score: 0.3946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [50:09<1:56:49, 1001.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2869 - accuracy: 0.1552 - f1_score: 0.2630 - val_loss: 0.2529 - val_accuracy: 0.2155 - val_f1_score: 0.3323\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2394 - accuracy: 0.2805 - f1_score: 0.3443 - val_loss: 0.2275 - val_accuracy: 0.3219 - val_f1_score: 0.3755\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2238 - accuracy: 0.3173 - f1_score: 0.3693 - val_loss: 0.2275 - val_accuracy: 0.3017 - val_f1_score: 0.3661\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2150 - accuracy: 0.3231 - f1_score: 0.3780 - val_loss: 0.2123 - val_accuracy: 0.3188 - val_f1_score: 0.3829\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 81s 999ms/step - loss: 0.2083 - accuracy: 0.3374 - f1_score: 0.3844 - val_loss: 0.2088 - val_accuracy: 0.3349 - val_f1_score: 0.3943\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 81s 1000ms/step - loss: 0.2014 - accuracy: 0.3463 - f1_score: 0.3980 - val_loss: 0.2055 - val_accuracy: 0.3364 - val_f1_score: 0.3869\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.1959 - accuracy: 0.3549 - f1_score: 0.4042 - val_loss: 0.2047 - val_accuracy: 0.3354 - val_f1_score: 0.3886\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1917 - accuracy: 0.3638 - f1_score: 0.4118 - val_loss: 0.2025 - val_accuracy: 0.3188 - val_f1_score: 0.3956\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1869 - accuracy: 0.3706 - f1_score: 0.4179 - val_loss: 0.2017 - val_accuracy: 0.3453 - val_f1_score: 0.3993\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1818 - accuracy: 0.3811 - f1_score: 0.4266 - val_loss: 0.2017 - val_accuracy: 0.3328 - val_f1_score: 0.3950\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1784 - accuracy: 0.3899 - f1_score: 0.4320 - val_loss: 0.1981 - val_accuracy: 0.3458 - val_f1_score: 0.4003\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1740 - accuracy: 0.3982 - f1_score: 0.4403 - val_loss: 0.2005 - val_accuracy: 0.3432 - val_f1_score: 0.3950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [1:06:34<1:39:29, 994.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2828 - accuracy: 0.1621 - f1_score: 0.2727 - val_loss: 0.2498 - val_accuracy: 0.2918 - val_f1_score: 0.3487\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2376 - accuracy: 0.2870 - f1_score: 0.3483 - val_loss: 0.2281 - val_accuracy: 0.3235 - val_f1_score: 0.3611\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2214 - accuracy: 0.3133 - f1_score: 0.3676 - val_loss: 0.2187 - val_accuracy: 0.3281 - val_f1_score: 0.3671\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 81s 997ms/step - loss: 0.2130 - accuracy: 0.3236 - f1_score: 0.3777 - val_loss: 0.2128 - val_accuracy: 0.3323 - val_f1_score: 0.3765\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2068 - accuracy: 0.3346 - f1_score: 0.3891 - val_loss: 0.2086 - val_accuracy: 0.3359 - val_f1_score: 0.3886\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 81s 997ms/step - loss: 0.2017 - accuracy: 0.3390 - f1_score: 0.3961 - val_loss: 0.2056 - val_accuracy: 0.3551 - val_f1_score: 0.3876\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1954 - accuracy: 0.3569 - f1_score: 0.4043 - val_loss: 0.2113 - val_accuracy: 0.3557 - val_f1_score: 0.3822\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1911 - accuracy: 0.3515 - f1_score: 0.4086 - val_loss: 0.2016 - val_accuracy: 0.3416 - val_f1_score: 0.4000\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 80s 991ms/step - loss: 0.1862 - accuracy: 0.3682 - f1_score: 0.4184 - val_loss: 0.2001 - val_accuracy: 0.3235 - val_f1_score: 0.3923\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 81s 999ms/step - loss: 0.1823 - accuracy: 0.3737 - f1_score: 0.4252 - val_loss: 0.2005 - val_accuracy: 0.3276 - val_f1_score: 0.3899\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 997ms/step - loss: 0.1783 - accuracy: 0.3882 - f1_score: 0.4323 - val_loss: 0.2023 - val_accuracy: 0.3598 - val_f1_score: 0.3953\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 81s 996ms/step - loss: 0.1741 - accuracy: 0.3888 - f1_score: 0.4364 - val_loss: 0.1973 - val_accuracy: 0.3458 - val_f1_score: 0.3956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [1:22:55<1:22:29, 989.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 87s 1s/step - loss: 0.2875 - accuracy: 0.1536 - f1_score: 0.2701 - val_loss: 0.2491 - val_accuracy: 0.2051 - val_f1_score: 0.3343\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2396 - accuracy: 0.2648 - f1_score: 0.3412 - val_loss: 0.2297 - val_accuracy: 0.2850 - val_f1_score: 0.3631\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2248 - accuracy: 0.3081 - f1_score: 0.3616 - val_loss: 0.2219 - val_accuracy: 0.3297 - val_f1_score: 0.3749\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2159 - accuracy: 0.3172 - f1_score: 0.3759 - val_loss: 0.2119 - val_accuracy: 0.3100 - val_f1_score: 0.3779\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2090 - accuracy: 0.3350 - f1_score: 0.3863 - val_loss: 0.2119 - val_accuracy: 0.2954 - val_f1_score: 0.3856\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2031 - accuracy: 0.3363 - f1_score: 0.3920 - val_loss: 0.2134 - val_accuracy: 0.3323 - val_f1_score: 0.3775\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1991 - accuracy: 0.3430 - f1_score: 0.4005 - val_loss: 0.2044 - val_accuracy: 0.3396 - val_f1_score: 0.3987\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.1933 - accuracy: 0.3516 - f1_score: 0.4099 - val_loss: 0.2069 - val_accuracy: 0.3328 - val_f1_score: 0.3973\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.1892 - accuracy: 0.3621 - f1_score: 0.4131 - val_loss: 0.2009 - val_accuracy: 0.3339 - val_f1_score: 0.4007\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1841 - accuracy: 0.3738 - f1_score: 0.4247 - val_loss: 0.2017 - val_accuracy: 0.3505 - val_f1_score: 0.3973\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1790 - accuracy: 0.3853 - f1_score: 0.4317 - val_loss: 0.2038 - val_accuracy: 0.3094 - val_f1_score: 0.3883\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.1756 - accuracy: 0.3856 - f1_score: 0.4356 - val_loss: 0.1985 - val_accuracy: 0.3505 - val_f1_score: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [1:39:30<1:06:06, 991.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.2894 - accuracy: 0.1562 - f1_score: 0.2678 - val_loss: 0.2537 - val_accuracy: 0.1952 - val_f1_score: 0.3225\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2407 - accuracy: 0.2739 - f1_score: 0.3405 - val_loss: 0.2331 - val_accuracy: 0.3105 - val_f1_score: 0.3651\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2259 - accuracy: 0.3052 - f1_score: 0.3634 - val_loss: 0.2219 - val_accuracy: 0.3214 - val_f1_score: 0.3678\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2154 - accuracy: 0.3212 - f1_score: 0.3773 - val_loss: 0.2133 - val_accuracy: 0.3313 - val_f1_score: 0.3792\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2082 - accuracy: 0.3298 - f1_score: 0.3866 - val_loss: 0.2134 - val_accuracy: 0.3126 - val_f1_score: 0.3842\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2034 - accuracy: 0.3381 - f1_score: 0.3938 - val_loss: 0.2066 - val_accuracy: 0.3427 - val_f1_score: 0.3893\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1981 - accuracy: 0.3428 - f1_score: 0.3968 - val_loss: 0.2061 - val_accuracy: 0.3474 - val_f1_score: 0.3950\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.1939 - accuracy: 0.3534 - f1_score: 0.4114 - val_loss: 0.2040 - val_accuracy: 0.3183 - val_f1_score: 0.3903\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1898 - accuracy: 0.3591 - f1_score: 0.4122 - val_loss: 0.2011 - val_accuracy: 0.3100 - val_f1_score: 0.3920\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.1850 - accuracy: 0.3762 - f1_score: 0.4229 - val_loss: 0.2028 - val_accuracy: 0.3370 - val_f1_score: 0.3970\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1798 - accuracy: 0.3775 - f1_score: 0.4294 - val_loss: 0.2010 - val_accuracy: 0.3245 - val_f1_score: 0.3893\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1759 - accuracy: 0.3912 - f1_score: 0.4372 - val_loss: 0.2005 - val_accuracy: 0.3577 - val_f1_score: 0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [1:56:56<50:28, 1009.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2861 - accuracy: 0.1493 - f1_score: 0.2636 - val_loss: 0.2532 - val_accuracy: 0.2175 - val_f1_score: 0.3306\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.2402 - accuracy: 0.2704 - f1_score: 0.3443 - val_loss: 0.2294 - val_accuracy: 0.3287 - val_f1_score: 0.3685\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.2243 - accuracy: 0.2982 - f1_score: 0.3618 - val_loss: 0.2220 - val_accuracy: 0.3157 - val_f1_score: 0.3598\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.2151 - accuracy: 0.3122 - f1_score: 0.3741 - val_loss: 0.2122 - val_accuracy: 0.3032 - val_f1_score: 0.3749\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.2081 - accuracy: 0.3237 - f1_score: 0.3849 - val_loss: 0.2108 - val_accuracy: 0.3416 - val_f1_score: 0.3863\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.2017 - accuracy: 0.3432 - f1_score: 0.3966 - val_loss: 0.2057 - val_accuracy: 0.3385 - val_f1_score: 0.3909\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1963 - accuracy: 0.3482 - f1_score: 0.4023 - val_loss: 0.2051 - val_accuracy: 0.3339 - val_f1_score: 0.3903\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1918 - accuracy: 0.3591 - f1_score: 0.4101 - val_loss: 0.2039 - val_accuracy: 0.3297 - val_f1_score: 0.3956\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1874 - accuracy: 0.3707 - f1_score: 0.4205 - val_loss: 0.2029 - val_accuracy: 0.3541 - val_f1_score: 0.3960\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1837 - accuracy: 0.3729 - f1_score: 0.4224 - val_loss: 0.2027 - val_accuracy: 0.3427 - val_f1_score: 0.3950\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1790 - accuracy: 0.3830 - f1_score: 0.4300 - val_loss: 0.1988 - val_accuracy: 0.3198 - val_f1_score: 0.3973\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 81s 1s/step - loss: 0.1745 - accuracy: 0.3845 - f1_score: 0.4354 - val_loss: 0.1999 - val_accuracy: 0.3255 - val_f1_score: 0.3990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:13:31<33:29, 1004.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 86s 1s/step - loss: 0.2896 - accuracy: 0.1509 - f1_score: 0.2610 - val_loss: 0.2604 - val_accuracy: 0.2181 - val_f1_score: 0.2951\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2429 - accuracy: 0.2728 - f1_score: 0.3388 - val_loss: 0.2298 - val_accuracy: 0.3037 - val_f1_score: 0.3631\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 97s 1s/step - loss: 0.2257 - accuracy: 0.3120 - f1_score: 0.3640 - val_loss: 0.2231 - val_accuracy: 0.3183 - val_f1_score: 0.3722\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 93s 1s/step - loss: 0.2159 - accuracy: 0.3194 - f1_score: 0.3771 - val_loss: 0.2171 - val_accuracy: 0.3136 - val_f1_score: 0.3795\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2090 - accuracy: 0.3289 - f1_score: 0.3856 - val_loss: 0.2150 - val_accuracy: 0.3411 - val_f1_score: 0.3852\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 92s 1s/step - loss: 0.2042 - accuracy: 0.3374 - f1_score: 0.3924 - val_loss: 0.2060 - val_accuracy: 0.2866 - val_f1_score: 0.3883\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.1985 - accuracy: 0.3390 - f1_score: 0.3998 - val_loss: 0.2037 - val_accuracy: 0.3401 - val_f1_score: 0.3933\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.1936 - accuracy: 0.3564 - f1_score: 0.4072 - val_loss: 0.2046 - val_accuracy: 0.3520 - val_f1_score: 0.3943\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 106s 1s/step - loss: 0.1883 - accuracy: 0.3716 - f1_score: 0.4174 - val_loss: 0.2002 - val_accuracy: 0.3660 - val_f1_score: 0.3960\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.1842 - accuracy: 0.3730 - f1_score: 0.4215 - val_loss: 0.1991 - val_accuracy: 0.3723 - val_f1_score: 0.4054\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1799 - accuracy: 0.3846 - f1_score: 0.4316 - val_loss: 0.2001 - val_accuracy: 0.3484 - val_f1_score: 0.3990\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1754 - accuracy: 0.3888 - f1_score: 0.4339 - val_loss: 0.1980 - val_accuracy: 0.3567 - val_f1_score: 0.3983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [2:31:56<17:16, 1036.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/12\n",
      "81/81 [==============================] - 88s 1s/step - loss: 0.2896 - accuracy: 0.1466 - f1_score: 0.2610 - val_loss: 0.2539 - val_accuracy: 0.2850 - val_f1_score: 0.3309\n",
      "Epoch 2/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2425 - accuracy: 0.2714 - f1_score: 0.3427 - val_loss: 0.2292 - val_accuracy: 0.2871 - val_f1_score: 0.3591\n",
      "Epoch 3/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2245 - accuracy: 0.3083 - f1_score: 0.3637 - val_loss: 0.2213 - val_accuracy: 0.2902 - val_f1_score: 0.3715\n",
      "Epoch 4/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.2156 - accuracy: 0.3164 - f1_score: 0.3727 - val_loss: 0.2139 - val_accuracy: 0.3224 - val_f1_score: 0.3762\n",
      "Epoch 5/12\n",
      "81/81 [==============================] - 85s 1s/step - loss: 0.2090 - accuracy: 0.3292 - f1_score: 0.3866 - val_loss: 0.2119 - val_accuracy: 0.3313 - val_f1_score: 0.3832\n",
      "Epoch 6/12\n",
      "81/81 [==============================] - 83s 1s/step - loss: 0.2027 - accuracy: 0.3359 - f1_score: 0.3915 - val_loss: 0.2073 - val_accuracy: 0.3214 - val_f1_score: 0.3903\n",
      "Epoch 7/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1967 - accuracy: 0.3511 - f1_score: 0.4010 - val_loss: 0.2056 - val_accuracy: 0.3489 - val_f1_score: 0.3913\n",
      "Epoch 8/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1923 - accuracy: 0.3532 - f1_score: 0.4090 - val_loss: 0.2086 - val_accuracy: 0.3427 - val_f1_score: 0.3926\n",
      "Epoch 9/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1872 - accuracy: 0.3689 - f1_score: 0.4158 - val_loss: 0.2010 - val_accuracy: 0.3354 - val_f1_score: 0.3980\n",
      "Epoch 10/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1827 - accuracy: 0.3829 - f1_score: 0.4285 - val_loss: 0.2017 - val_accuracy: 0.3442 - val_f1_score: 0.3920\n",
      "Epoch 11/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1782 - accuracy: 0.3873 - f1_score: 0.4333 - val_loss: 0.1999 - val_accuracy: 0.3172 - val_f1_score: 0.3923\n",
      "Epoch 12/12\n",
      "81/81 [==============================] - 82s 1s/step - loss: 0.1735 - accuracy: 0.3982 - f1_score: 0.4402 - val_loss: 0.1981 - val_accuracy: 0.3645 - val_f1_score: 0.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:49:22<00:00, 1016.22s/it]\n"
     ]
    }
   ],
   "source": [
    "save_folder = \"Models/EnsemblingModels/\"\n",
    "train_model_ensembling(train_dataset, Y_train, save_folder, no_of_reps = 10, epochs_per_model = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7hk7XrAr49P"
   },
   "source": [
    "## Loading trained models for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlncD3lngjF-",
    "outputId": "30052d29-7658-4edb-fcae-ba573d850208"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:12<01:48, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5218424962852897\n",
      "Model Precision on test data is: 0.4347610794751176\n",
      "Model Recall on test data is: 0.6525455221107395\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:23<01:33, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5059981544140265\n",
      "Model Precision on test data is: 0.4072790294627383\n",
      "Model Recall on test data is: 0.6678846934632562\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:34<01:20, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5266676355180933\n",
      "Model Precision on test data is: 0.44862589749938103\n",
      "Model Recall on test data is: 0.6375791695988741\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:45<01:08, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5526827912149014\n",
      "Model Precision on test data is: 0.49220103986135183\n",
      "Model Recall on test data is: 0.6301109350237718\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:57<00:57, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5414084507042254\n",
      "Model Precision on test data is: 0.4758603614756128\n",
      "Model Recall on test data is: 0.6278993792878145\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:08<00:45, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5164375373580395\n",
      "Model Precision on test data is: 0.4278286704629859\n",
      "Model Recall on test data is: 0.6513381078024878\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [01:20<00:34, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5249630723781389\n",
      "Model Precision on test data is: 0.4399603862342164\n",
      "Model Recall on test data is: 0.6506774075430245\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [01:31<00:22, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5483196206944637\n",
      "Model Precision on test data is: 0.4867541470661055\n",
      "Model Recall on test data is: 0.6277139208173691\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [01:43<00:11, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5334291876347951\n",
      "Model Precision on test data is: 0.4592720970537262\n",
      "Model Recall on test data is: 0.6361454046639232\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:54<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.537841726618705\n",
      "Model Precision on test data is: 0.462738301559792\n",
      "Model Recall on test data is: 0.6420474063895568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model F1 on test data is: 0.5334917570176742\n",
      "Model Precision on test data is: 0.44466452092102005\n",
      "Model Recall on test data is: 0.6666666666666666\n",
      "(10, 1926, 20)\n",
      "Max F1 score of all reps: 0.5526827912149014\n",
      "Average F1 score of all reps: 0.5309590672820678\n",
      "F1 Score from ALL Models' predictions AVERAGED: 0.5334917570176742\n",
      "Precision Score from ALL Models' predictions AVERAGED: 0.44466452092102005\n",
      "Recall Score from ALL Models' predictions AVERAGED: 0.6666666666666666\n",
      "-----\n",
      "Applying confidence thresholding- F1 score of selected predictions: 0.6385964912280702\n",
      "Predictions Refused: 1658\n",
      "-----\n",
      "Applying frequentist methods - F1 score of selected predictions: 0.6356756756756756\n",
      "Predictions Refused: 1638\n"
     ]
    }
   ],
   "source": [
    "path = 'Models/EnsemblingModels/'\n",
    "avg_prediction_array, std_prediction_array, f1_list = eval_model_ensembling(path, 10, test_dataset,Y_test, 0.5, 100, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycKjgY87hF3C"
   },
   "source": [
    "## Single Sample Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dStbk4DlhIhc",
    "outputId": "eaa670db-8ade-429a-a05e-e9987af54bab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:02<00:19,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:04<00:16,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:07<00:17,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:09<00:13,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:11<00:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:14<00:09,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:19<00:09,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:22<00:06,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:25<00:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Majority Vote Prediction of all models: \n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Ground truth Value: \n",
      "[[0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n",
      "Ground truth class labels: \n",
      "['Adevnture Novel', 'Romance Novel', 'Crime Fiction']\n",
      "Final prediction after confidence interval thresholding: \n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Confidence factors for each class: \n",
      "( 0.00010382275734871537 ,  0.001975175855356903 )\n",
      "( -1.968875906742539e-05 ,  0.00015530112426050835 )\n",
      "( 0.010755567629868889 ,  0.03686081785238276 )\n",
      "( 0.45438969949598346 ,  0.6549543656933781 )\n",
      "( -0.028337194125005696 ,  0.2170137197774143 )\n",
      "( 0.0005557563757182232 ,  0.00616859464015503 )\n",
      "( 0.3135220321615584 ,  0.5193205503026598 )\n",
      "( 0.0002768824963020689 ,  0.006433783153432369 )\n",
      "( 0.0010490995757527935 ,  0.006153985585992755 )\n",
      "( 0.0015170950254814542 ,  0.01408595626257194 )\n",
      "( 0.4058630784447494 ,  0.6182283321921525 )\n",
      "( 3.5886263349782684e-05 ,  0.00046351285506669433 )\n",
      "( 0.1001209466608381 ,  0.33926533322016245 )\n",
      "( 0.0025534499431957014 ,  0.019293110399041653 )\n",
      "( -2.6667081428207676e-05 ,  0.004508111286585667 )\n",
      "( 0.009867477779740647 ,  0.08994890377903525 )\n",
      "( -0.0002624966510576909 ,  0.005726968923491031 )\n",
      "( 0.1149450286195705 ,  0.24262500117559932 )\n",
      "( 0.013627272497393681 ,  0.06520609964849751 )\n",
      "( 0.0005346958699903297 ,  0.02015339888750698 )\n",
      "prediction fails - IGNORED\n",
      "CPU times: user 14.9 s, sys: 1.49 s, total: 16.4 s\n",
      "Wall time: 27.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_folder = 'Models/EnsemblingModels/'\n",
    "avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor = single_EN_pred(models_folder, 10, test_dataset[245], Y_test[245], 0.5, 20, 400, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi5VfER4dMxx"
   },
   "source": [
    "# BNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior posterior defenitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWBMJkKgdgc_"
   },
   "outputs": [],
   "source": [
    "# Define the prior weight distribution as Normal of mean=0 and stddev=1.\n",
    "# Note that, in this example, the we prior distribution is not trainable,\n",
    "# as we fix its parameters.\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.DistributionLambda(\n",
    "                lambda t: tfp.distributions.MultivariateNormalDiag(\n",
    "                     loc=tf.fill(dims = (n,), value = 0.5), scale_diag=tf.fill(dims = (n,), value = 0.5)#loc=tf.zeros(n), scale_diag=tf.ones(n)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return prior_model\n",
    "\n",
    "\n",
    "# Define variational posterior weight distribution as multivariate Gaussian.\n",
    "# Note that the learnable parameters for this distribution are the means,\n",
    "# variances, and covariances.\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = keras.Sequential(\n",
    "        [\n",
    "            tfp.layers.VariableLayer(\n",
    "                tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype\n",
    "            ),\n",
    "            tfp.layers.MultivariateNormalTriL(n),\n",
    "        ]\n",
    "    )\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding matrix generation with different dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qgYBUCPgali",
    "outputId": "64815490-5e4d-40b8-f45c-ecb6c04cdfcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "embed_size = 300\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3sJIHIwgqpU"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19aIOC1Kdm8f"
   },
   "outputs": [],
   "source": [
    "def get_bnn_model(train_size):\n",
    "    initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "    model = tf.keras.models.Sequential(name = \"BNN_Model_with_priors\")\n",
    "    model.add(tf.keras.layers.Embedding(nb_words+1, output_dim=300, weights=[embedding_matrix], input_length = maxlen, trainable=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.1)) # embedding dropouts\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, recurrent_dropout = 0.5, activation = 'tanh', kernel_initializer=initializer)))# weight drop on recurrent layers using recurrent_dropout\n",
    "    # model.add(tf.keras.layers.LSTM(128, return_sequences=True, recurrent_dropout = 0.5, activation = 'tanh', kernel_initializer=initializer)) \n",
    "    # model.add(tf.keras.layers.LSTM(256, return_sequences=True, recurrent_dropout = 0.5, activation = 'tanh', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D(data_format=\"channels_last\", keepdims=False))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(512, kernel_initializer=initializer, activation='relu'))\n",
    "    # model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tfp.layers.DenseVariational(units = 16, make_prior_fn = prior, make_posterior_fn = posterior, kl_weight = 1 / train_size, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(20, kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "    # model.add(tfp.layers.IndependentLogistic(event_shape=(20, )))\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=False) , optimizer = 'adam', metrics = ['accuracy', tfa.metrics.F1Score(num_classes = 20, average = 'micro')])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNN Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1lhafU3dtqc"
   },
   "outputs": [],
   "source": [
    "def Eval_BNN_Model(model, no_of_reps, X_test, Y_test, threshold_value, confidence_threshold, conf_perc_factor):\n",
    "    \"\"\"\n",
    "    Runs over no_of_reps times to create different models using BNN and\n",
    "    predicts a different set of probabilites during each repetition.\n",
    "    \n",
    "    Returns average of all predictions taken over no_of_reps number of predict-\n",
    "    ions, stanadard deviation across all predictions taken over no_of_reps num-\n",
    "    ber of predictions and the F1 score for each model.\n",
    "    \"\"\"\n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    f1_list = [] # array of shape no_of_reps x 1 (F1 score)\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, Y_test.shape[0], Y_test.shape[1])) # 3D array to store all no_of_reps number of different prediction values\n",
    "    # model = tf.keras.models.load_model(save_path)\n",
    "    \n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        predictions = model.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        model_f1 = eval_model(thresholded_predictions, Y_test) # returns f1 of model\n",
    "        f1_list.append(model_f1)\n",
    "    avg_f1 = np.mean(np.array(f1_list), axis = 0)\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape no_of_samples x no_of_classes (Average stddev of all reps)\n",
    "    now = datetime.datetime.now()\n",
    "    name = '/content/drive/MyDrive/GenreClassificationBayes/'+str(now.month)+\"-\"+str(now.day)+\"-\"+str(now.hour)+\"-\"+str(now.minute)+\"_\"+str(no_of_reps)+\"_\" # file nomenclature\n",
    "    pd.DataFrame(avg_prediction_array).to_csv(name+'average_preds.csv', index = False, header = None)\n",
    "    pd.DataFrame(std_prediction_array).to_csv(name+'std_preds.csv', index = False, header = None) # saving prediction avg and std over no_of_reps\n",
    "    # Fequentist calculation\n",
    "    final_predictions_freq = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            avg = avg_prediction_array[i,j]\n",
    "            std = std_prediction_array[i,j]\n",
    "            lower_lim = avg - conf_level_factor*std\n",
    "            upper_lim = avg + conf_level_factor*std\n",
    "            if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "                final_predictions_freq[i,j] = 1\n",
    "            elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "                final_predictions_freq[i,j] = 0\n",
    "            else: \n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_predictions_freq.append(final_predictions_freq[i])\n",
    "            selected_Y_vals_freq.append(Y_test[i])\n",
    "    # Frequentist calculation ends\n",
    "    avg_thresholded_predictions = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    avg_pred_f1 = eval_model(avg_thresholded_predictions, Y_test, printing = False) # returns f1 of Averaged predictions from no_of_reps models\n",
    "    avg_pred_precision = precision_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    avg_pred_recall = recall_score(avg_thresholded_predictions, Y_test, average='micro')\n",
    "    all_prediction_array_thresholded = threshold_predictions(all_prediction_array, threshold_value)\n",
    "    confidence_matrix = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    final_predictions_maj_vote = np.zeros(shape = (Y_test.shape[0], Y_test.shape[1]))\n",
    "    print(all_prediction_array_thresholded.shape)\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            no_of_zeros = 0\n",
    "            no_of_ones = 0\n",
    "            for k in range(no_of_reps):\n",
    "                if all_prediction_array_thresholded[k,i,j] == 0:\n",
    "                    no_of_zeros += 1\n",
    "                elif all_prediction_array_thresholded[k,i,j] == 1:\n",
    "                    no_of_ones += 1\n",
    "            if no_of_ones > no_of_zeros:\n",
    "                confidence_matrix[i, j] = no_of_ones/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 1\n",
    "            else:\n",
    "                confidence_matrix[i, j] = no_of_zeros/no_of_reps * 100\n",
    "                final_predictions_maj_vote[i, j] = 0\n",
    "    thresholded_confidence_predictions = []\n",
    "    selected_ground_truth_values = []\n",
    "    for i in range(Y_test.shape[0]):\n",
    "        flag = 0\n",
    "        for j in range(Y_test.shape[1]):\n",
    "            if confidence_matrix[i, j] < confidence_threshold:\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            thresholded_confidence_predictions.append(final_predictions_maj_vote[i])\n",
    "            selected_ground_truth_values.append(Y_test[i])\n",
    "    avg_f1_conf_thresholded = eval_model(np.array(thresholded_confidence_predictions), np.array(selected_ground_truth_values), printing = False)\n",
    "    f1_maj_vote = eval_model(np.array(final_predictions_maj_vote), Y_test, printing = False)\n",
    "\n",
    "    print(\"Max F1 score of all reps: \"+str(max(f1_list)))\n",
    "    print(\"Average F1 score of all reps: \"+str(avg_f1))\n",
    "    print(\"F1 Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_f1))\n",
    "    print(\"Precision Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_precision))\n",
    "    print(\"Recall Score from ALL Models' predictions AVERAGED: \"+str(avg_pred_recall))\n",
    "    print(\"-----\\nApplying confidence thresholding - F1 score of selected predictions: \"+str(avg_f1_conf_thresholded))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_ground_truth_values).shape[0]))\n",
    "    print(\"-----\\nApplying frequentist methods - F1 score of selected predictions: \"+str(selected_freq_preds_f1))\n",
    "    print(\"Predictions Refused: \"+str(Y_test.shape[0] - np.array(selected_Y_vals_freq).shape[0]))\n",
    "    print(\"Majority vote F1:\"+str(f1_maj_vote))\n",
    "    return avg_prediction_array, std_prediction_array, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPyl950UeH3X"
   },
   "outputs": [],
   "source": [
    "def single_BNN_pred(cur_model, no_of_reps, X_test, Y_test, threshold_value, num_classes, maxlen_embedding, conf_perc_factor):\n",
    "    if X_test.shape is not (1, maxlen_embedding):\n",
    "        X_test = np.reshape(X_test, (1, maxlen_embedding))\n",
    "    if Y_test.shape is not (1, num_classes):\n",
    "        Y_test = np.reshape(Y_test, (1, num_classes))\n",
    "    all_prediction_array = np.zeros(shape = (no_of_reps, 1, num_classes)) # 3D array to store all no_of_reps number of different prediction values\n",
    "    confidence_count_zero = [0 for i in range(num_classes)]\n",
    "    confidence_count_one = [0 for i in range(num_classes)]\n",
    "    confidence_factor = [0 for i in range(num_classes)]\n",
    "    final_prediction_MV = [0 for i in range(num_classes)]\n",
    "    loaded_model = cur_model\n",
    "    # loaded_model = tf.keras.models.load_model(save_path)\n",
    "    for i in tqdm(range(no_of_reps)):\n",
    "        predictions = loaded_model.predict(X_test)\n",
    "        all_prediction_array[i] = predictions\n",
    "        thresholded_predictions = threshold_predictions(predictions, threshold_value)\n",
    "        print(thresholded_predictions)\n",
    "        for i in range(thresholded_predictions.shape[1]):\n",
    "            if thresholded_predictions[0][i] == 0:\n",
    "                confidence_count_zero[i] += 1\n",
    "            else:\n",
    "                confidence_count_one[i] += 1\n",
    "    for i in range(num_classes):\n",
    "        if confidence_count_zero[i] > confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_zero[i] / no_of_reps)*100\n",
    "        elif confidence_count_zero[i] < confidence_count_one[i]:\n",
    "            confidence_factor[i] = (confidence_count_one[i] / no_of_reps)*100\n",
    "            final_prediction_MV[i] = 1\n",
    "        else:\n",
    "            confidence_factor[i] =  50.0\n",
    "    avg_prediction_array = np.mean(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average predictions of all reps)\n",
    "    std_prediction_array = np.std(all_prediction_array, axis = 0) # shape 1 x no_of_classes (Average stddev of all reps)\n",
    "    # frequentist starts \n",
    "    conf_level_factor = np.sqrt(2) * erfinv(conf_perc_factor)\n",
    "    final_predictions_freq = np.zeros(shape = (1, num_classes))\n",
    "    thresholded_predictions_freq = []\n",
    "    selected_Y_vals_freq = []\n",
    "    lower_lim_array = []\n",
    "    upper_lim_array = []\n",
    "    flag = 0\n",
    "    for j in range(num_classes):\n",
    "        avg = avg_prediction_array[0,j]\n",
    "        std = std_prediction_array[0,j]\n",
    "        lower_lim = avg - conf_level_factor*std\n",
    "        upper_lim = avg + conf_level_factor*std\n",
    "        lower_lim_array.append(lower_lim)\n",
    "        upper_lim_array.append(upper_lim)\n",
    "        if lower_lim > threshold_value and upper_lim > threshold_value:\n",
    "            final_predictions_freq[0,j] = 1\n",
    "        elif lower_lim < threshold_value and upper_lim < threshold_value:\n",
    "            final_predictions_freq[0,j] = 0\n",
    "        else: \n",
    "            flag = 1\n",
    "    if flag == 0:\n",
    "        thresholded_predictions_freq.append(final_predictions_freq[0])\n",
    "    #frequentist ends\n",
    "    avg_prediction_thresholded = threshold_predictions(avg_prediction_array, threshold_value)\n",
    "    genres_list = ['Spy Fiction', 'Alternate History', 'Non Fiction', 'Adevnture Novel', 'Detective Fiction', 'Historical Fiction', 'Romance Novel', 'Horror', 'Thriller', 'Historical Novel', 'Crime Fiction', 'Suspense', 'Young Adult Literature', 'Mystery', 'Childrens Literature', 'Fantasy', 'Novel', 'Science Fiction', 'Speculative Fiction', 'Fiction']\n",
    "    answer_list = []\n",
    "    ground_truth_list = []\n",
    "    for i in range(20):\n",
    "        if avg_prediction_thresholded[0][i] == 1:\n",
    "            answer_list.append(genres_list[i])\n",
    "        if Y_test[0][i] == 1:\n",
    "            ground_truth_list.append(genres_list[i])\n",
    "    # print(\"Average Prediction of all models Thresholded: \")\n",
    "    # print(avg_prediction_thresholded)\n",
    "    # print(\"Classes Predicted: \")\n",
    "    # print(answer_list)\n",
    "    print(\"Majority Vote Prediction of all models: \")\n",
    "    print(final_prediction_MV)\n",
    "    print(\"Ground truth Value: \")\n",
    "    print(Y_test)\n",
    "    print(\"Ground truth class labels: \")\n",
    "    print(ground_truth_list)\n",
    "    print(\"Final prediction after confidence interval thresholding: \")\n",
    "    print(final_predictions_freq)\n",
    "    print(\"Confidence factors for each class: \")\n",
    "    for i in range(num_classes):\n",
    "        print(\"(\",lower_lim_array[i],\", \",upper_lim_array[i],\")\")\n",
    "    if flag == 0:\n",
    "        print(\"Prediction passes - CONSIDERED\")\n",
    "    else:\n",
    "        print(\"prediction fails - IGNORED\")\n",
    "    # print(\"Confidence Factors for each class in %: \")\n",
    "    # print(confidence_factor)\n",
    "    # print(\"Overall average confidence factor for prediction: \"+str(np.mean(np.array(confidence_factor))))\n",
    "    return avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expt(model, train_dataset, Y_train, val_dataset, Y_val, test_dataset):\n",
    "\n",
    "    print(\"Starting model training.\")\n",
    "    model.fit(train_dataset, Y_train, epochs=num_epochs, validation_data=(val_dataset, Y_val))\n",
    "    print(\"Model training finished.\")\n",
    "    loss, acc, f1  = model.evaluate(train_dataset, Y_train, verbose=0)\n",
    "    print(f\"Train results: {round(loss, 3)}, {round(acc, 3)}, {round(f1, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    loss, acc, f1 = model.evaluate(test_dataset, Y_test, verbose=0)\n",
    "    print(f\"Test results: {round(loss, 3)}, {round(acc, 3)}, {round(f1, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = get_bnn_model(len(train_dataset))\n",
    "run_expt(new_model, train_dataset, Y_train, val_dataset, Y_val, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_model.save_weights(\"Models/bnn_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Saved Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKH6VdWod5KM",
    "outputId": "a384b809-5327-4844-c72e-0ebd9e196e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "new_model = get_bnn_model(len(train_dataset))\n",
    "new_model.load_weights(\"Models/bnn_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5iBKFETeAEM"
   },
   "outputs": [],
   "source": [
    "apa, spa, f = Eval_BNN_Model(new_model, 10, test_dataset, Y_test, 0.08693312, 100, 0.90 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaylplMseUCf"
   },
   "source": [
    "## Single Sample BNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06kJFQrGeTbx",
    "outputId": "d7418732-e282-4933-f025-95b3290aa304"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:00<00:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:01<00:02,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:01<00:02,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:01<00:01,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:02<00:01,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:02<00:01,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:02<00:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:03<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "Majority Vote Prediction of all models: \n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Ground truth Value: \n",
      "[[0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n",
      "Ground truth class labels: \n",
      "['Adevnture Novel', 'Romance Novel', 'Crime Fiction']\n",
      "Final prediction after confidence interval thresholding: \n",
      "[[0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]]\n",
      "Confidence factors for each class: \n",
      "( 0.04796163661857207 ,  0.2555953383586828 )\n",
      "( 0.03526183239457961 ,  0.28384800233604557 )\n",
      "( 0.20363885848753274 ,  0.3215742877221841 )\n",
      "( 0.08495674161401581 ,  0.4101674486866872 )\n",
      "( 0.023676623703732635 ,  0.22751546025107844 )\n",
      "( 0.19241470676570413 ,  0.3098147155651522 )\n",
      "( 0.38981662613218765 ,  0.4356504001014854 )\n",
      "( 0.04452851300933042 ,  0.23780866304538567 )\n",
      "( 0.09769014022615531 ,  0.2941817323181333 )\n",
      "( 0.05538221818615238 ,  0.2596905686218616 )\n",
      "( 0.1795514446420427 ,  0.4112981456594709 )\n",
      "( 0.010870755846569616 ,  0.22756453937762017 )\n",
      "( 0.24689771178314712 ,  0.33032351490905254 )\n",
      "( 0.09460607436749201 ,  0.3112664464369132 )\n",
      "( 0.13097546897607987 ,  0.2905776421002751 )\n",
      "( 0.24186093283673388 ,  0.35104564355830087 )\n",
      "( 0.015225810698508244 ,  0.21597646889156202 )\n",
      "( 0.10716415737604156 ,  0.32788448537851317 )\n",
      "( 0.08896957541156539 ,  0.28635113632034537 )\n",
      "( 0.12954904875070739 ,  0.29187439391105485 )\n",
      "prediction fails - IGNORED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "avg_prediction_array, std_prediction_array, avg_prediction_thresholded, final_prediction_MV, confidence_factor = single_BNN_pred(new_model, 10, test_dataset[245], Y_test[245], 0.08693312, 20, 400, 0.90)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HSeSpcCxXtxY",
    "P9V9i6M1XvfF",
    "ZWn44vlRfuHH",
    "zB1WYOFBgC1h",
    "C8rJROH_WGbQ",
    "eckuxzKSXDuj",
    "VWFZb4UhXJdc",
    "c0N-vEs4XAtm",
    "1xdD2_aSaPZB",
    "7TdNmCKKWYiv",
    "CBmYpMilWhLn",
    "9cHVThvOWbi2",
    "qhi47Lz_inP-",
    "VYOX8p80X7Ws",
    "XN2Aec1sYY5j",
    "lvpXMhjjDir9",
    "al1saT-CD-vD",
    "MrDdgPV_TCV4",
    "3dCvGlpcK8M3",
    "kiIe8k4SEd0K",
    "LterLVJMQPdT",
    "Htrz4fBhgRBk",
    "3dIUg1xhr0zC",
    "q7hk7XrAr49P",
    "ycKjgY87hF3C",
    "avjDnLQWRDEN",
    "o2_bVc4BIGSi",
    "PScZ3-edS6Gi",
    "Gi5VfER4dMxx",
    "iaylplMseUCf"
   ],
   "name": "Porting_TF.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
